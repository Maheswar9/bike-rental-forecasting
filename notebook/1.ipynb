{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c6b8f18",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing necessary libraries\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import StandardScaler \n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn import linear_model\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "np.random.seed(42)\n",
    "\n",
    "\n",
    "# --- Load the final, feature-rich dataset ---\n",
    "# This file already contains the 17 columns needed for the project.\n",
    "try:\n",
    "    bikes_final_df = pd.read_csv('../data/hour.csv')\n",
    "    print(\"Successfully loaded the final dataset (hour.csv).\")\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: 'hour.csv' not found. Please make sure it is in the correct directory.\")\n",
    "    exit()\n",
    "\n",
    "\n",
    "# Let's look at the columns to confirm it matches the list you provided.\n",
    "print(\"\\nColumns in the final dataset:\")\n",
    "print(bikes_final_df.columns)\n",
    "\n",
    "# Display the first few rows to see the data\n",
    "print(\"\\nFirst 5 rows of the final dataset:\")\n",
    "print(bikes_final_df.head())\n",
    "\n",
    "# Use .info() to see the data types and non-null counts\n",
    "print(\"\\nDataset Information:\")\n",
    "bikes_final_df.info()\n",
    "\n",
    "# Display the data type of every column in the DataFrame\n",
    "print(bikes_final_df.dtypes)\n",
    "bikes_final_df.info()\n",
    "# Select the 'season' column from the DataFrame\n",
    "season_series = bikes_final_df['season']\n",
    "\n",
    "# Use the .unique() function to find all the unique values in that column\n",
    "unique_seasons = season_series.unique()\n",
    "\n",
    "# Print the unique values\n",
    "print(\"The unique values in the 'season' column are:\")\n",
    "print(unique_seasons)\n",
    "bikes_final_df.describe()\n",
    "#Cleaning the data - Dropping unwanted features \n",
    "columnsToDrop = ['instant','casual','registered','atemp','dteday']\n",
    "\n",
    "bikesData = bikes_final_df.drop(columns=columnsToDrop)\n",
    "print(bikesData.columns)\n",
    "#Divide into training/ test dataset \n",
    "bikesData['dayCount'] = pd.Series(range(bikesData.shape[0]))/24\n",
    "\n",
    "train_set, test_set = train_test_split(bikesData, test_size=0.3, random_state=42)\n",
    "\n",
    "print(len(train_set), \"train +\", len(test_set), \"test\")\n",
    "\n",
    "train_set.sort_values('dayCount', axis= 0, inplace=True)\n",
    "test_set.sort_values('dayCount', axis= 0, inplace=True)\n",
    "def display_scores(scores):\n",
    "    print(\"Scores:\", scores)\n",
    "    print(\"Mean:\", scores.mean())\n",
    "    print(\"Standard deviation:\", scores.std())\n",
    "#Feature Scaling \n",
    "columnsToScale = ['temp','hum','windspeed']\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "train_set[columnsToScale] = scaler.fit_transform(train_set[columnsToScale])\n",
    "test_set[columnsToScale] = scaler.transform(test_set[columnsToScale])\n",
    "train_set[columnsToScale].describe()\n",
    "# Preparing to Train the Models \n",
    "%pip install xgboost\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import xgboost\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "trainingCols = train_set.drop(['cnt'], axis=1)\n",
    "trainingLabels = train_set['cnt']\n",
    "print(\"\\nShape of the training features (trainingCols):\", trainingCols.shape)\n",
    "print(\"Shape of the training labels (trainingLabels):\", trainingLabels.shape)\n",
    "print(\"\\nFirst 5 rows of training features:\")\n",
    "print(trainingCols.head())\n",
    "#Train and Analyze the Models \n",
    "#Train a Decision Tree Regressor\n",
    "\n",
    "dec_reg = DecisionTreeRegressor(random_state = 42)\n",
    "\n",
    "dt_mae_scores = -cross_val_score(dec_reg, trainingCols, trainingLabels, cv=10, scoring=\"neg_mean_absolute_error\")\n",
    "\n",
    "display_scores(dt_mae_scores)\n",
    "\n",
    "dt_mse_scores = np.sqrt(-cross_val_score(dec_reg, trainingCols, trainingLabels, cv=10, scoring=\"neg_mean_squared_error\"))\n",
    "\n",
    "display_scores(dt_mse_scores)\n",
    "#Train a Linear Regression model\n",
    "\n",
    "lin_reg = LinearRegression()\n",
    "\n",
    "lr_mae_scores = -cross_val_score(lin_reg, trainingCols, trainingLabels, cv=10, scoring=\"neg_mean_absolute_error\")\n",
    "\n",
    "display_scores(lr_mae_scores)\n",
    "\n",
    "lr_mse_scores = np.sqrt(-cross_val_score(lin_reg, trainingCols, trainingLabels, cv=10, scoring=\"neg_mean_squared_error\"))\n",
    "\n",
    "display_scores(lr_mse_scores)\n",
    "#Train a Random Forest Regressor\n",
    "\n",
    "forest_reg = RandomForestRegressor(n_estimators=150, random_state=42)\n",
    "\n",
    "rf_mae_scores = -cross_val_score(forest_reg, trainingCols, trainingLabels, cv=10, scoring=\"neg_mean_absolute_error\")\n",
    "\n",
    "display_scores(rf_mae_scores)\n",
    "\n",
    "rf_mse_scores = np.sqrt(-cross_val_score(forest_reg, trainingCols, trainingLabels, cv=10, scoring=\"neg_mean_squared_error\"))\n",
    "\n",
    "display_scores(rf_mse_scores)\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = [\n",
    "    # try combinations of hyperparameters\n",
    "    {'n_estimators': [120, 150], 'max_features': [10, 12], 'max_depth': [15, 28]},\n",
    "]\n",
    "#Fine-Tuning the Random Forest Regressor\n",
    "# Using GridSearchCV to find the best hyperparameters for the Random Forest Regressor\n",
    "grid_search = GridSearchCV(forest_reg, param_grid, cv=5, scoring='neg_mean_squared_error')\n",
    "#Run GridSearchCV\n",
    "grid_search.fit(trainingCols, trainingLabels)\n",
    "\n",
    "print(grid_search.best_estimator_)\n",
    "print(grid_search.best_params_)\n",
    "feature_importances = grid_search.best_estimator_.feature_importances_\n",
    "print(feature_importances)\n",
    "#Preparing to test the final model on Test dataset \n",
    "final_model = grid_search.best_estimator_\n",
    "test_set.sort_values('dayCount', axis= 0, inplace=True)\n",
    "test_x_cols = (test_set.drop(['cnt'], axis=1)).columns.values\n",
    "test_y_cols = 'cnt'\n",
    "\n",
    "X_test = test_set.loc[:,test_x_cols]\n",
    "y_test = test_set.loc[:,test_y_cols]\n",
    "# Make Predictions on the Test dataset using Final Model\n",
    "test_set.loc[:,'predictedCounts_test'] = final_model.predict(X_test)\n",
    "\n",
    "mse = mean_squared_error(y_test, test_set.loc[:,'predictedCounts_test'])\n",
    "final_mse = np.sqrt(mse)\n",
    "print(final_mse)\n",
    "test_set.describe()\n",
    "times = [9,18]\n",
    "for time in times:\n",
    "    fig = plt.figure(figsize=(8, 6))\n",
    "    fig.clf()\n",
    "    ax = fig.gca()\n",
    "    test_set_freg_time = test_set[test_set.hr == time]\n",
    "    test_set_freg_time.plot(kind = 'line', x = 'dayCount', y = 'cnt', ax = ax)\n",
    "    test_set_freg_time.plot(kind = 'line', x = 'dayCount', y = 'predictedCounts_test', ax =ax)\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
